{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ‰ Welcome to the FiftyOne Project in Google Colab! ðŸŽ‰\n",
        "ðŸš€ **FiftyOne** is an open-source toolkit for exploring, visualizing, and managing your datasets, making it easier to work with images and machine learning workflows.\n",
        "\n",
        "## ðŸ”¹ Features:\n",
        "âœ… Easily browse and filter large datasets  \n",
        "âœ… Powerful visualization tools for images and annotations  \n",
        "âœ… Integration with deep learning frameworks like TensorFlow and PyTorch  \n",
        "\n",
        "## ðŸ“Œ Setup Instructions:\n",
        "Run the following command to install FiftyOne if you haven't already:  \n",
        "```python\n",
        "!pip install fiftyone\n",
        "!pio install databases\n",
        "\n"
      ],
      "metadata": {
        "id": "aYUMFbYdKXn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import fiftyone as fo\n",
        "    print(\"âœ… FiftyOne is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"ðŸ“¦ Installing FiftyOne...\")\n",
        "    %pip install -q fiftyone\n",
        "\n",
        "# Verify installation\n",
        "!pip list | grep -i fiftyone\n",
        "\n",
        "try:\n",
        "    import datasets\n",
        "    print(\"âœ… datasets is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"ðŸ“¦ Installing datasets...\")\n",
        "    %pip install -q datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset from Hugging Face using datasets\n",
        "hf_dataset = load_dataset(\"TeeA/nutrition5k-food-name-gemini\")\n",
        "\n",
        "# To check the data being succesffully loaded\n",
        "# hf_dataset['train'][0]\n",
        "# dir(hf_dataset['train'])"
      ],
      "metadata": {
        "id": "PQeMPS29IRFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Create a list to store samples\n",
        "samples = []\n",
        "\n",
        "# Define the directory to save images\n",
        "image_dir = \"images\"\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "  # Create a FiftyOne dataset\n",
        "dataset = fo.Dataset(\"food_dataset\", overwrite=True)\n",
        "\n",
        "for data in hf_dataset['train']:\n",
        "# Save the image to disk\n",
        "  image_path = os.path.join(image_dir, f\"{data['dish_id']}.png\")\n",
        "  data['dish_image'].save(image_path)\n",
        "\n",
        "  # Create a FiftyOne sample\n",
        "  sample = fo.Sample(filepath=image_path)\n",
        "  sample['dish_id'] = data['dish_id']\n",
        "\n",
        "  # Add food_name as a Classification field\n",
        "  sample['food_name'] = fo.Classification(label=data['food_name'].strip())\n",
        "\n",
        "  # Add the sample to the list\n",
        "  samples.append(sample)\n",
        "\n",
        "  # Add samples to the dataset\n",
        "dataset.add_samples(samples)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c-1ofpC5USDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset_filtered = fo.Dataset.from_images_dir(\"images\")\n",
        "session = fo.launch_app(hf_dataset_filtered)"
      ],
      "metadata": {
        "id": "L4Yi88ReY2NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset_filtered\n"
      ],
      "metadata": {
        "id": "KjXSKuxSuHVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}